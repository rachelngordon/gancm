{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import loss\n",
    "import tensorflow.keras as kr\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(kr.layers.Layer): \n",
    "    def __init__(self, \n",
    "                 num_channels, \n",
    "                 use_1x1conv=False, \n",
    "                 strides=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = kr.layers.Conv2D(\n",
    "            num_channels, padding='same', kernel_size=3, strides=strides,\n",
    "            kernel_initializer = kr.initializers.GlorotNormal())\n",
    "        self.conv2 = kr.layers.Conv2D(\n",
    "            num_channels, kernel_size=3, padding='same',\n",
    "            kernel_initializer = kr.initializers.GlorotNormal())\n",
    "        self.conv3 = None\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = kr.layers.Conv2D(\n",
    "                num_channels, kernel_size=1, strides=strides,\n",
    "                kernel_initializer = kr.initializers.GlorotNormal())\n",
    "        self.bn1 = kr.layers.GroupNormalization(groups=num_channels)\n",
    "        self.bn2 = kr.layers.GroupNormalization(groups=num_channels)\n",
    "        #self.bn1 = kr.layers.BatchNormalization()\n",
    "        #self.bn2 = kr.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, X):\n",
    "        Y = kr.activations.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3 is not None:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return kr.activations.relu(Y)\n",
    "\n",
    "\n",
    "class ResidualT(kr.layers.Layer): \n",
    "    def __init__(self, \n",
    "                 num_channels, \n",
    "                 strides=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = kr.layers.Conv2DTranspose(\n",
    "            num_channels, padding='same', kernel_size=4, strides=strides,\n",
    "            kernel_initializer = kr.initializers.GlorotNormal())\n",
    "       \n",
    "        self.bn1 = kr.layers.GroupNormalization(groups=num_channels)\n",
    "        #self.bn1 = kr.layers.BatchNormalization()\n",
    "     \n",
    "\n",
    "    def call(self, X):\n",
    "        return kr.activations.relu(self.bn1(self.conv1(X)))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(kr.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 num_channels, \n",
    "                 num_residuals, \n",
    "                 first_block=False,\n",
    "                 **kwargs):\n",
    "        super(ResnetBlock, self).__init__(**kwargs)\n",
    "        self.residual_layers = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                x = Residual(num_channels, use_1x1conv=True, strides=2)\n",
    "                self.residual_layers.append(x)\n",
    "            else:\n",
    "                x = Residual(num_channels)\n",
    "                self.residual_layers.append(x)\n",
    "\n",
    "    def call(self, X):\n",
    "        for layer in self.residual_layers.layers:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "class ResnetBlockT(kr.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 num_channels, \n",
    "                 num_residuals, \n",
    "                 **kwargs):\n",
    "        super(ResnetBlockT, self).__init__(**kwargs)\n",
    "        self.residual_layers = []\n",
    "        for i in range(num_residuals):\n",
    "            x = ResidualT(num_channels, strides=2)\n",
    "            self.residual_layers.append(x)\n",
    "\n",
    "    def call(self, X):\n",
    "        for layer in self.residual_layers.layers:\n",
    "            X = layer(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderModule(kr.Model): \n",
    "    def __init__(self, \n",
    "                 channels, \n",
    "                 filter_size,  \n",
    "                 image_shape,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        #define encoder\n",
    "        self.encoder = kr.models.Sequential()\n",
    "        self.encoder._name = \"Encoder\"\n",
    "\n",
    "        #first conv\n",
    "        self.b1 = [kr.layers.Conv2D(channels, kernel_size=5, strides=2, padding='same', \n",
    "                                    input_shape=image_shape, name=\"Conv1\"),\n",
    "                   kr.layers.GroupNormalization(groups=channels, name='BN1'),\n",
    "                   #kr.layers.BatchNormalization(name='BN1'),\n",
    "                   kr.layers.Activation('relu', name='Relu'),\n",
    "                   kr.layers.MaxPool2D(pool_size=3, strides=2, \n",
    "                                       padding='same', name='MaxPool')]\n",
    "        \n",
    "        for layer in self.b1:\n",
    "            self.encoder.add(layer)\n",
    "\n",
    "        #second block\n",
    "        b2 = ResnetBlock(channels, 2, first_block=True)\n",
    "        b2._name ='ResBlock_2'\n",
    "        self.encoder.add(b2)\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            b = ResnetBlock(int(2 ** (i + 6)), 2)\n",
    "            b._name = f\"ResBlock_{i+2}\"\n",
    "            self.encoder.add(b)\n",
    "\n",
    "    def call(self, inputs__):\n",
    "        return self.encoder(inputs__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "256\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 8):\n",
    "    if i < 4:\n",
    "        print(int(2 ** (i + 6)))\n",
    "    else:\n",
    "        print(int(2 ** (3 + 6)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderModule(kr.Model): \n",
    "    def __init__(self, \n",
    "                 channels, \n",
    "                 filter_size,  \n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        #define encoder\n",
    "        self.decoder = kr.models.Sequential()\n",
    "        self.decoder._name = \"Decoder\"\n",
    "        self.decoder.add(ResnetBlockT(channels//4, 1))\n",
    "        self.decoder.add(ResnetBlockT(channels//2, 1))\n",
    "        self.decoder.add(ResnetBlockT(channels//2, 1))\n",
    "        self.decoder.add(ResnetBlockT(channels, 1))\n",
    "\n",
    "\n",
    "    def call(self, inputs__):\n",
    "        return self.decoder(inputs__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class p2p_generator(kr.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.encoder = EncoderModule(channels=64, \n",
    "                                        filter_size=3,\n",
    "                                        image_shape=(256,256,1))\n",
    "        \n",
    "        self.decoder = DecoderModule(channels=256, \n",
    "                                        filter_size=4)\n",
    "        \n",
    "        self.convT = kr.layers.Conv2DTranspose(1, \n",
    "                                               5, \n",
    "                                               strides=2, \n",
    "                                               padding='same')\n",
    "        \n",
    "\n",
    "    def call(self, input__):\n",
    "        return kr.activations.sigmoid(self.convT(self.decoder(self.encoder(input__))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(kr.Model):\n",
    "\tdef __init__(self, flags, **kwargs):\n",
    "\t\tsuper().__init__(**kwargs)\n",
    "\t\tself.image_shape = (flags.crop_size, flags.crop_size, 1)\n",
    "\t\tn_filters = flags.disc_n_filters\n",
    "\t\tfilter_size = flags.disc_filter_size\n",
    "\t\tself.merged = kr.layers.Concatenate()\n",
    "\t\tself.downsample1 = Residual(n_filters, use_1x1conv=True, strides=2)\n",
    "\t\tself.downsample2 = ResnetBlock(2*n_filters, 1)\n",
    "\t\tself.downsample3 = ResnetBlock(4*n_filters, 1)\n",
    "\t\tself.downsample4 = ResnetBlock(8*n_filters, 1)\n",
    "\t\tself.conv = kr.layers.Conv2D(self.image_shape[-1], kernel_size=filter_size, padding='same')\n",
    "        \n",
    "\t\n",
    "\tdef call(self, inputs_, **kwargs):\n",
    "\t\t#print(f\"{'=='.join(['#' for i in range (10)])}\\n{inputs_[0].shape},\\n {inputs_[1].shape}\")\n",
    "\t\tx = self.merged([inputs_[0], inputs_[1]])\n",
    "\t\tx1 = self.downsample1(x)\n",
    "\t\tx2 = self.downsample2(x1)\n",
    "\t\tx3 = self.downsample3(x2)\n",
    "\t\tx4 = self.downsample4(x3)\n",
    "\t\tx5 = self.conv(x4)\n",
    "\t\treturn [x1, x2, x3, x4, x5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P2PMonitor(kr.callbacks.Callback):\n",
    "\tdef __init__(self, val_dataset, flags, my_strategy=False):\n",
    "\t\tself.val_images = next(iter(val_dataset))\n",
    "\t\tself.my_strategy = my_strategy\n",
    "\t\tself.n_samples = 1\n",
    "\t\tself.epoch_interval = 2\n",
    "\t\tself.checkpoints_path = os.path.join(flags.checkpoints_dir, flags.name)\n",
    "\t\tself.sample_dir = os.path.join(flags.sample_dir, flags.name)\n",
    "\n",
    "\t\tif not os.path.exists(self.checkpoints_path):\n",
    "\t\t\tos.makedirs(self.checkpoints_path)\n",
    "\t\tif not os.path.exists(self.sample_dir):\n",
    "\t\t\tos.makedirs(self.sample_dir)\n",
    "\n",
    "\tdef infer(self):\n",
    "\t\tif self.my_strategy:\n",
    "\t\t\t#@tf.function\n",
    "\t\t\tdef inferx(c):\n",
    "\t\t\t\treturn self.model(c)\n",
    "\t\t\t\t\n",
    "\t\t\tall_replicas = self.my_strategy.experimental_local_results(self.val_images)\n",
    "\t\t\tself.val_images = all_replicas[0]\n",
    "\t\t\tpredictions = inferx(self.val_images[0])\n",
    "\t\t\t#print(f\"\\n{self.val_images[0].shape}\")\n",
    "\t\t\t#values = self.my_strategy.experimental_local_results(predictions)\n",
    "\t\t\treturn predictions\n",
    "\t\telse:\n",
    "\t\t\t\n",
    "\t\t\treturn self.model(self.val_images[0])\n",
    "\n",
    "\tdef on_epoch_end(self, epoch, logs=None):\n",
    "\t\tif epoch > 0 and epoch % self.epoch_interval == 0:\n",
    "\t\t\t#self.save_models()\n",
    "\t\t\tgenerated_images = self.infer()\n",
    "\t\t\tfor s_ in range(self.n_samples):\n",
    "\t\t\t\tgrid_row = min(generated_images.shape[0], 3)\n",
    "\t\t\t\tf, axarr = plt.subplots(grid_row, 3, figsize=(18, grid_row * 6))\n",
    "\t\t\t\tfor row in range(grid_row):\n",
    "\t\t\t\t\tax = axarr if grid_row == 1 else axarr[row]\n",
    "\t\t\t\t\tax[0].imshow((self.val_images[0][row].numpy().squeeze()), cmap='gray')\n",
    "\t\t\t\t\tax[0].axis(\"off\")\n",
    "\t\t\t\t\tax[0].set_title(\"CT\", fontsize=20)\n",
    "\t\t\t\t\tax[1].imshow((self.val_images[1][row].numpy().squeeze()), cmap='gray')\n",
    "\t\t\t\t\tax[1].axis(\"off\")\n",
    "\t\t\t\t\tax[1].set_title(\"Ground Truth\", fontsize=20)\n",
    "\t\t\t\t\tax[2].imshow((np.array(generated_images[row]).squeeze()), cmap='gray')\n",
    "\t\t\t\t\tax[2].axis(\"off\")\n",
    "\t\t\t\t\tax[2].set_title(\"Generated\", fontsize=20)\n",
    "\t\t\t\tfilename = \"sample_{}_{}_{}.png\".format(epoch, s_, datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\t\t\t\tsample_file = os.path.join(self.sample_dir, filename)\n",
    "\t\t\t\tplt.savefig(sample_file)\n",
    "\t\t\t\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Flags():\n",
    "    def __int__(self):\n",
    "        self.initialized = False\n",
    "        self.initalize()\n",
    "        return 0\n",
    "\n",
    "    def initalize(self):\n",
    "        self.apply_normalization= False                          \n",
    "        self.batch_size= 1                              \n",
    "        self.checkpoints_dir= './checkpoints'                  \n",
    "        self.crop_size= 256                            \n",
    "        self.d_res_filters= 1024                           \n",
    "        self.data_path= '/media/aisec1/DATA3/rachel/PCGAN/data/folds1234.npz' \n",
    "        self.data_test_rate= 0.2                            \n",
    "        self.disc_beta_1= 0.0                            \n",
    "        self.disc_beta_2= 0.999                          \n",
    "        self.disc_filter_size= 4                              \n",
    "        self.disc_lr= 0.0001                         \n",
    "        self.disc_n_filters= 64                             \n",
    "        self.disc_strides= 2                              \n",
    "        self.e_filter_size= 3                              \n",
    "        self.e_n_filters= 64                             \n",
    "        self.e_strides= 2                              \n",
    "        self.edge_threshold= 0.03                           \n",
    "        self.epoch_interval= 2                             \n",
    "        self.epochs= 10                            \n",
    "        self.feature_loss_coeff= 10.0                           \n",
    "        self.gen_beta_1= 0.0                            \n",
    "        self.gen_beta_2= 0.999                          \n",
    "        self.gen_lr= 0.0001                         \n",
    "        self.gpu_ids= 1                             \n",
    "        self.isTrain= True                      \n",
    "        self.kl_divergence_loss_coeff= 0.1                            \n",
    "        latent_dim= 256                            \n",
    "        self.load_from_opt_file= False                          \n",
    "        self.load_size= 256                            \n",
    "        self.loss_weights= [1 , 100]                       \n",
    "        self.model_path= '/media/aisec1/DATA3/rachel/PCGAN/models/Pix2Pix_fold1234' \n",
    "        self.name= 'pix2pix_fold1234'                   \n",
    "        self.phase= 'train'                          \n",
    "        self.remove_bad_images= True                           \n",
    "        self.result_log= 'results.log'                    \n",
    "        self.result_logs= './results'                     \n",
    "        self.s_beta_filter_size= 3                              \n",
    "        self.s_beta_filters= 128                            \n",
    "        self.s_epsilon= 1e-05                          \n",
    "        self.s_gamma_filter_size= 3                              \n",
    "        self.s_gamma_filters= 128                            \n",
    "        self.sample_dir= './training_samples'             \n",
    "        self.test_data_path= '/media/aisec1/DATA3/Bibo2/Project/CT2MRI/dataset/CV/fold5.npz' \n",
    "        self.vgg_feature_loss_coeff= 0.1  \n",
    "\n",
    "        print('done!')\n",
    "        return 0\n",
    "\n",
    "\n",
    "flags = Flags()\n",
    "flags.initalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class pix2pix(kr.Model):\n",
    "    def __init__(self, flags,strategy=False, **kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        self.experiment_name = \"debugp2p\" #flags.name\n",
    "        self.flags = flags\n",
    "        #self.samples_dir = flags.sample_d\n",
    "        #self.models_dir = flags.checkpoints_dir\n",
    "        self.image_shape = (256, 256, 1) #(flags.crop_size, flags.crop_size, 1)\n",
    "        self.image_size = 256 #flags.crop_size\n",
    "        self.batch_size = 1 #flags.batch_size\n",
    "\n",
    "        self.feature_loss_coeff = 4 #flags.feature_loss_coeff\n",
    "        self.vgg_feature_loss_coeff = 1 #flags.vgg_feature_loss_coeff\n",
    "        self.generator_loss_coeff = 1\n",
    "        self.ssim_loss_coeff = 2\n",
    "        self.mae_loss_coeff = 10\n",
    "        \n",
    "        self.discriminator = Discriminator(flags)\n",
    "        self.generator = p2p_generator()\n",
    "        self.patch_size, self.combined_model = self.build_combined_model()\n",
    "        # gen_lr = 0.0002, gen_beta_1 = 0.5\n",
    "        self.generator_optimizer = kr.optimizers.Adam(self.flags.gen_lr, beta_1=self.flags.gen_beta_1)\n",
    "        self.discriminator_optimizer = kr.optimizers.Adam(self.flags.disc_lr, beta_1=self.flags.gen_beta_1)\n",
    "        self.discriminator_loss = loss.DiscriminatorLoss()\n",
    "        self.feature_matching_loss = loss.FeatureMatchingLoss()\n",
    "        self.vgg_loss = loss.VGGFeatureMatchingLoss()\n",
    "        self.mae_loss = loss.MAE()\n",
    "\n",
    "        self.disc_loss_tracker = tf.keras.metrics.Mean(name=\"disc_loss\")\n",
    "        self.gen_loss_tracker = tf.keras.metrics.Mean(name=\"gen_loss\")\n",
    "        self.feat_loss_tracker = tf.keras.metrics.Mean(name=\"feat_loss\")\n",
    "        self.vgg_loss_tracker = tf.keras.metrics.Mean(name=\"vgg_loss\")\n",
    "        self.ssim_loss_tracker = tf.keras.metrics.Mean(name=\"ssim_loss\")\n",
    "        self.mae_loss_tracker = tf.keras.metrics.Mean(name=\"mae_loss\")\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.disc_loss_tracker,\n",
    "            self.gen_loss_tracker,\n",
    "            self.feat_loss_tracker,\n",
    "            self.vgg_loss_tracker,\n",
    "            self.ssim_loss_tracker,\n",
    "            self.mae_loss_tracker]\n",
    "\n",
    "    def build_combined_model(self):\n",
    "\n",
    "        self.discriminator.trainable = False\n",
    "        ct_input = kr.Input(shape=self.image_shape, name=\"ct\")\n",
    "        mri_input = kr.Input(shape=self.image_shape, name=\"mri\")\n",
    "\n",
    "        generated_mri = self.generator(ct_input)\n",
    "        \n",
    "        #print(generated_mri.shape)\n",
    "\n",
    "        discriminator_outputs = self.discriminator([ct_input, generated_mri])\n",
    "        patch_size = discriminator_outputs[-1].shape[1]\n",
    "        combined_model = kr.Model(\n",
    "            [ct_input, mri_input],\n",
    "            [discriminator_outputs, generated_mri])\n",
    "\n",
    "        return patch_size, combined_model\n",
    "\n",
    "\n",
    "    def compile(self, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "\n",
    "    def train_discriminator(self, ct, real_mri):\n",
    "        \n",
    "        fake_mri = self.generator(ct)\n",
    "        with tf.GradientTape() as gradient_tape:\n",
    "            pred_fake = self.discriminator([ct, fake_mri])[-1]  # check\n",
    "            pred_real = self.discriminator([ct, real_mri])[-1]  # check\n",
    "            #print(f\"{'#'.join(['#' for i in range(20)])}\\n\\n{pred_real.shape}\\n\\n\")\n",
    "            #fake_labels = np.zeros((1,16,16,1), dtype=int)\n",
    "            #real_lables = np.ones((1,16,16,1), dtype=int)\n",
    "            loss_fake = self.discriminator_loss(False, pred_fake)\n",
    "            loss_real = self.discriminator_loss(True, pred_real)\n",
    "            total_loss = 0.5 * (loss_fake + loss_real)\n",
    "\n",
    "        self.discriminator.trainable = True\n",
    "        gradients = gradient_tape.gradient(\n",
    "            total_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "\n",
    "        self.discriminator_optimizer.apply_gradients(\n",
    "            zip(gradients, self.discriminator.trainable_variables)\n",
    "        )\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def train_generator(self, ct, mri__):\n",
    "\n",
    "        self.discriminator.trainable = False\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_d_output, fake_mri = self.combined_model([ct, mri__])\n",
    "            real_d_output = self.discriminator([ct, mri__])  # check\n",
    "\n",
    "            #fake_d_output = fake_d_output[-1].shape[1]\n",
    "            pred = fake_d_output[-1]\n",
    "            \n",
    "            # Compute generator loss\n",
    "            g_loss = self.generator_loss_coeff*loss.generator_loss(pred)\n",
    "            vgg_loss = self.vgg_feature_loss_coeff * self.vgg_loss(mri__, fake_mri)\n",
    "            feature_loss = self.feature_loss_coeff * self.feature_matching_loss(\n",
    "                real_d_output, fake_d_output\n",
    "            )\n",
    "            ssim_loss = self.ssim_loss_coeff * loss.SSIMLoss(mri__, fake_mri)\n",
    "            mae_loss = self.mae_loss_coeff * self.mae_loss(mri__, fake_mri)\n",
    "            total_loss = g_loss + vgg_loss + feature_loss + ssim_loss + mae_loss\n",
    "            \n",
    "        all_trainable_variables = (\n",
    "            self.combined_model.trainable_variables\n",
    "        )\n",
    "\n",
    "        gradients = tape.gradient(total_loss, all_trainable_variables)\n",
    "\n",
    "        self.generator_optimizer.apply_gradients(\n",
    "            zip(gradients, all_trainable_variables)\n",
    "        )\n",
    "\n",
    "        return total_loss, vgg_loss, feature_loss, ssim_loss, mae_loss\n",
    "\n",
    "\n",
    "    def train_step(self, data):\n",
    "\n",
    "        ct, mri = data\n",
    "        \n",
    "        discriminator_loss = self.train_discriminator(ct, mri)\n",
    "        (generator_loss, vgg_loss, feature_loss, ssim_loss, mae_loss) = self.train_generator(ct, mri)\n",
    "\n",
    "        # Report progress.\n",
    "        self.disc_loss_tracker.update_state(discriminator_loss)\n",
    "        self.gen_loss_tracker.update_state(generator_loss)\n",
    "        self.feat_loss_tracker.update_state(feature_loss)\n",
    "        self.vgg_loss_tracker.update_state(vgg_loss)\n",
    "        self.ssim_loss_tracker.update_state(ssim_loss)\n",
    "        self.mae_loss_tracker.update_state(mae_loss)\n",
    "\n",
    "\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "    def test_step(self, data):\n",
    "\n",
    "        ct, mri = data\n",
    "        fake_mri = self.generator(ct)\n",
    "\n",
    "        # Calculate the losses.\n",
    "        pred_fake = self.discriminator([ct, fake_mri])[-1]  # check\n",
    "        pred_real = self.discriminator([ct, mri])[-1]  # check\n",
    "        #print(f\"{'#'.join(['#' for i in range(20)])}\\n\\n{pred_real.shape}\\n\\n\")\n",
    "#         fake_labels = np.zeros((1,16,16,1), dtype=int)\n",
    "#         real_lables = np.ones((1,16,16,1), dtype=int)\n",
    "        loss_fake = self.discriminator_loss(False, pred_fake)\n",
    "        loss_real = self.discriminator_loss(True, pred_real)\n",
    "        total_discriminator_loss = 0.5 * (loss_fake + loss_real)\n",
    "\n",
    "        real_d_output = self.discriminator([fake_mri, mri])\n",
    "        fake_d_output, fake_image = self.combined_model([ct, mri])\n",
    "        pred = fake_d_output[-1]\n",
    "        g_loss = self.generator_loss_coeff*loss.generator_loss(pred)\n",
    "        \n",
    "        vgg_loss = self.vgg_feature_loss_coeff * self.vgg_loss(mri, fake_image)\n",
    "        feature_loss = self.feature_loss_coeff * self.feature_matching_loss(\n",
    "            real_d_output, fake_d_output)\n",
    "        ssim_loss = self.ssim_loss_coeff * loss.SSIMLoss(mri, fake_image)\n",
    "        mae_loss = self.mae_loss_coeff * self.mae_loss(mri, fake_mri)\n",
    "        total_generator_loss = g_loss + vgg_loss + feature_loss + ssim_loss + mae_loss\n",
    "\n",
    "        # Report progress.\n",
    "        self.disc_loss_tracker.update_state(total_discriminator_loss)\n",
    "        self.gen_loss_tracker.update_state(total_generator_loss)\n",
    "        self.feat_loss_tracker.update_state(feature_loss)\n",
    "        self.vgg_loss_tracker.update_state(vgg_loss)\n",
    "        self.ssim_loss_tracker.update_state(ssim_loss)\n",
    "        self.mae_loss_tracker.update_state(mae_loss)\n",
    "\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "        return results\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.generator(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build and train the model\n",
    "\n",
    "model = pix2pix(flags)\n",
    "model.compile()\n",
    "model.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loader\n",
    "\n",
    "test_dataset = data_loader.DataGenerator_PairedReady(flags, '/media/aisec-102/DATA3/Bibo2/Project/CT2MRI/dataset/CV/fold5.npz').load()\n",
    "train_dataset = data_loader.DataGenerator_PairedReady(flags, '/media/aisec-102/DATA3/rachel/PCGAN/data/folds1234.npz').load()\n",
    "\n",
    "#options = tf.data.Options()\n",
    "#options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.FILE\n",
    "\n",
    "#train_dataset = train_dataset.with_options(options)\n",
    "#test_dataset = test_dataset.with_options(options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "  train_dataset,\n",
    "  validation_data=test_dataset,\n",
    "  epochs=100,\n",
    "  callbacks=[P2PMonitor(test_dataset, flags)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
